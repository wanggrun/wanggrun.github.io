<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Guangrun Wang; 王广润; Machine Learning; Computer Vision; Sun Yat-sen University; SYSU; HCP">
<link rel="author" href="https://wanggrun.github.io/">

    <title>Guangrun Wang (王广润)'s Homepage</title>
    <style>

@media screen and (max-device-width: 1000px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #fff; }
.title { width : 880px; margin : 20px auto; }
.container { width : 1000px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 40px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="./homepage_files/analytics.js"></script>
</head>

<body>
    <div class="title">
        <div id="sidebar"><img src="./homepage_files/me.jpg" vspace="50 px" width="150 px" id="me" itemprop="photo"></div>
        <div id="bio">

            <br>

            <h1>
                <span itemprop="name">Guangrun Wang <font size="5">王广润</font> </span>
            </h1>

            <br>

            <p style="line-height:23px;">
                Postdoctoral Researcher  <a href="https://eng.ox.ac.uk/people/guangrun-wang/">(I am in Oxford</a>) (<a href="https://torrvision.com/people/">I am at TVG</a>)(<a href="https://wanggrun.github.io/projects/fast">FAST Lab</a>)
                <br>
                Department of Engineering Science, University of Oxford
                <br>
                Parks Road, Oxford, OX1 3PJ
                <br>
                wanggrun at gmail.com or guangrun.wang at eng.ox.ac.uk
                <br>
            </p>
            <p class="external">
                <a href="https://github.com/wanggrun/", class="first">GitHub</a><a href="https://wanggrun.github.io/projects/fast">Blog</a><a href="https://wanggrun.github.io/projects/ddl">DDL</a><a href="https://wanggrun.github.io/projects/pub">Publications</a><a href="https://wanggrun.github.io/projects/cv">CV</a><a href="https://wanggcong.github.io/">Related link</a><a href="https://torrvision.com/people/">TVG</a><a href="https://mp.weixin.qq.com/s?__biz=MzI5NDc0NzgzMg==&mid=2247485186&idx=2&sn=8e4e0a393b38b974f7dab7c387380a04&chksm=ec5f6cd5db28e5c3c868cb29bbe914be6b372cde691f633720e4b7e40ebdbd4ed41bce7b3aa1&mpshare=1&scene=24&srcid=1114J1ewMqhXj5yMAPYuTbn0&sharer_sharetime=1605324870719&sharer_shareid=b56edb57aa57c3b758ca8d3617256e4a&ascene=14&devicetype=android-29&version=3.1.1.6192&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&exportkey=A6sZXWnRni3hba9ujlVnv4g%3D&pass_ticket=UABTY4ewKMdf6I5clhj%2BKoArjqaRzmjfyTTKsAnrp8fyiCCUmg5EeoPSiY%2FqEamw&wx_header=1&platform=mac">PhD Thesis</a><a href="https://wanggrun.github.io/projects/zw">中文版本</a>
            </p>
		
        </div>
    </div>

    <div class="container">
        <h2>Short Bio</h2>
        <p>
            Guangrun Wang is currently a Postdoctoral Researcher in the <a href="https://eng.ox.ac.uk">Department of Engineering Science</a> at <a href="https://www.ox.ac.uk">University of Oxford</a>, working with Prof. <a href="https://www.robots.ox.ac.uk/~phst/">Philip H. S. Torr</a>. Before that, he was a PhD candidate in the <a href="http://www.sysu-hcp.net/home/">HCP</a> Lab of Sun Yat-sen University, advised by Prof. <a href="http://www.linliang.net/">Liang Lin</a>. He also worked as a visiting scholar in the <a href="http://mmlab.ie.cuhk.edu.hk/">MMLab</a> of The Chinese University of Hong Kong, mentored by Prof. <a href="http://luoping.me/"> Ping Luo</a> and Prof. <a href="http://www.ee.cuhk.edu.hk/~xgwang/">Xiaogang Wang</a>. 
            
            <br>
            <br>His research interest is machine learning. He has published more than 10 papers with about <font color="red"><b>1000</b></font> citations.
            
            <br>
            <br> His GPA is 95, ranking 1st in his class. He receives the 2018 Pattern Recognition Best Paper Award. He was awarded as an "Outstanding Student of Guangdong Province". He ranked 1st in 2015 Graduate Innovation Funding of The High Performance Computing Collaborative Innovation Center(only 7 graduate students were awarded in China that year). He won several worldwide competition medals such as Kaggle data mining gold/silver/bronze medals. He ranked 1st in PASCAL VOC segmentation leaderboard for months. His team ranked 2nd out of 2322 teams in FashionAI Global Challenge. He won two National Scholarships. He has two ESI Hightly Cited Paper. He was awarded as an outstanding reviewer of ICLR 2021. I am in the list of Top Chinese Rising Stars in Artificial Intelligence.
            
            <br>
            <br> I serve as a <b>Senior Program Committee for IJCAI, outstanding reviewer for ICLR, conference reviewer</b> for ICML / NeurIPS / ACL / ICCV / CVPR / AAAI / EMNLP / EACL / IJCNLP / NAACL / AACL / WACV / ACCV / PRCV, <b>journal reviewer</b> for ISPRS / T-PAMI / T-NNLS / T-IP / T-CSVT / PR / IEEE Access / ISPL / JVCI / AAS / IPM / IF / DT, and <b>TA</b> for Software Design/Computer Vision/Pattern Recoginition.

            <br>
            <br> He has obtained double Bachelor Degrees, including Engineering and Business.
            <br>
            <br><font color="red"><b>If you are interested in my research or would like to work with me as an intern in Oxford, feel free to contact me. </b></font>
       </p>
       <h2>News</h2>
       <p>
       I am in the list of Top Chinese Rising Stars in Artificial Intelligence. <font color="red"><b>NEW!</b></font>
       <br><br>
       I start to work at University of Oxford, joining <a href="https://torrvision.com/people/">TVG</a>. My commonly used e-mail becomes wanggrun at gmail.com or guangrun.wang at eng.ox.ac.uk. [<a href="https://www.ox.ac.uk">Go to University of Oxford</a>] <font color="red"><b>NEW!</b></font>
       <br><br>
       I have written an HTML page showing the deadline of the leading AI conferences in 2021. <a href="https://wanggrun.github.io/projects/ddl">"DDL of leading AI conferences".</a> <font color="red"><b>NEW!</b></font>
       <br><br>
       I have written new blogs <a href="https://wanggrun.github.io/projects/fast">《Snow in Oxford and Running in University Park》《基于投影条件判别器的条件GAN》《FAST Lab Logo正式发布》《我的思考：布朗运动处处不可导与未来神经网络》《3D表征学习和图像生成表征学习》《牛津大学TVG组招收一名实习访问学生》《你见过凌晨的牛津吗？》《FAST LAB开始公开写作啦》</a> <font color="red"><b>NEW!</b></font>
       <br><br>
       I have 9 patents now! [<a href="https://wanggrun.github.io/projects/pub"> patents </a>]
       <br><br>
       I was awarded as an outstanding reviewer of ICLR 2021. <font color="red"><b>NEW!</b></font>
       <br><br>
       Media reports:<a href="https://mp.weixin.qq.com/s?__biz=MzAxMzc2NDAxOQ==&mid=2650400061&idx=1&sn=e94532931bf75f5678986fe9f482f017&chksm=8390d1e1b4e758f7173ecdffe77407fe3bc62d089df2f7322d6af249a5685b58880ba5031d06&mpshare=1&&srcid=0405EYMg9g05RoOGc6m3WmHo&sharer_sharetime=1617602850856&sharer_shareid=b56edb57aa57c3b758ca8d3617256e4a&scene=2&subscene=2&clicktime=1617947329&enterid=1617947329&version=3.1.2.6203&platform=mac#rd">《CVPR'21 Oral | 动态slimmable网络：高性能的网络轻量化方法！对比slimmable涨点5.9%！》</a>
       <br><br>
       Media reports:<a href="https://mp.weixin.qq.com/s?__biz=MzAxMzc2NDAxOQ==&mid=2650399927&idx=1&sn=86c4c22ba69713156f7ebb07c8b79090&chksm=8390d06bb4e7597d0ba566968b7058486f6fb7cec4f7d989009010b61202842228a41c30015d&mpshare=1&srcid=040192qh0fV1PU4ZpsuA28ZT&sharer_sharetime=1617258518150&sharer_shareid=b56edb57aa57c3b758ca8d3617256e4a&scene=2&subscene=2&clicktime=1617953701&enterid=1617953701&ascene=2&devicetype=android-29&version=3.1.2.6203&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&exportkey=AzzTPzrXgZ4LIoilwzoagaU%3D&pass_ticket=2sz8MjhXFHP3QrUHrPCzyRV9vw1wAHyH6UzAKyQwbArUXt4UtAZJ7UWucCAN2dzw&wx_header=1&platform=mac">《不使用标签数据!自动搜索Transformer混合结构，同速度超过EfficientNet 2.1%！》</a>
       <br><br>
       I will serve as a reviewer of NeuRIPS 2021!
       <br><br>
       I will serve as a reviewer of EMNLP 2021!
       <br><br>
       I will serve as a reviewer of ICCV 2021!
       <br><br>
       I will serve as a reviewer of Defence Technology!
       <br><br>
       I will serve as a reviewer of NAACL 2021!
       <br><br>
       I have written a new blog on <a href="https://wanggrun.github.io/projects/story6">"Ensemble Learning of Super-Resolution".</a>
       <br><br>
       I will serve as a reviewer of ICML 2021!
       <br><br>
       I will serve as a reviewer of ACL 2021!
       <br><br>
       I will serve as a reviewer of T-NNLS!
       <br><br>
       Media reports:<a href="https://mp.weixin.qq.com/s/zN13vlygkUXOTTwrqQd0-w">《重磅！中山大学提出行人重识别新方法和史上最大数据集SYSU-30k，已开源！》</a>
       <br><br>
       Media reports:<a href="https://mp.weixin.qq.com/s/XsE0wBECzO6Mddtfdu8vVA">《可微图学习和弱监督：中山大学提出新型行人重识别方法和史上最大最新评测基准》</a>
       <br><br>
       The code and pretrained model of "Grammatically Recognizing Images with Tree Convolution" has been released. [<a href="https://github.com/wanggrun/TreeConv">Download the code and pretrained model</a>].
       <br><br>
       The dataset, code, and pretrained model of "Weakly Supervised Person Re-ID: Differentiable Graphical Learning and A New Benchmark" has been released. [<a href="https://github.com/wanggrun/SYSU-30k"> Download the dataset, code, and pretrained model</a>].
       <br><br>
       I will serve as SPC (Senior Program Committee members) for IJCAI 2021! "Only very senior experts are invited to be SPC, who will participate in the summary reject phase which is very crucial and we rely on academic judgment, responsibility, and dedication from senior researchers like you". [<a href="https://ijcai-21.org">IJCAI Senior Program Committee</a>] <font color="red"><b>NEW!</b></font>
       <br><br>
       I will serve as a reviewer of CVPR 2021!
       <br><br>
       I will serve as a reviewer of EACL 2021!
       <br><br>
       The code of "Transferable, Controllable, and Inconspicuous Adversarial Attacks on Person Re-identification With Deep Mis-Ranking" has been released. [<a href="https://github.com/whj363636/Adversarial-attack-on-Person-ReID-With-Deep-Mis-Ranking">Download the code and pretrained model</a>].
       <br><br>
       I will serve as a reviewer of Information Fusion (top journal, 中科院一区)
       <br><br>
       I will serve in Program Committee for AAAI 2021!
       <br><br>
       I will serve as a reviewer of IJCAI 2021!
       <br><br>
       I will serve as a reviewer of ICLR 2021!
       <br><br>
       My commonly used e-mail will be gradually changed into wanggrun at hotmail.com or wanggrun at gmail.com. Between them, hotmail is preferred due to the accessibility in China.<font color="red"><b>NEW!</b></font>
       <br><br>
       I have written a new blog on <a href="https://wanggrun.github.io/projects/story5">"What is the future of AI / ML?"</a>
       <br><br>
       The code and pretrained model of "EagleEye: Fast Sub-net Evaluation for Efficient Neural Network Pruning" has been released. [<a href="https://github.com/anonymous47823493/EagleEye">Download the code and pretrained model</a>]
       <br><br>
       One paper is accepted by ECCV 2020 as oral presentation (top 2%), one of the top conferences in computer vision.
       <br><br>
       I have served as a reviewer of EMNLP 2020!
       <br><br>
       I will serve as a reviewer of ACCV 2020!
       <br><br>
       I will serve as a reviewer of WACV 2020!
       <br><br>
       One paper is accepted by KDD 2020, the top-1 conference in data mining.
       <br><br>
       One paper is accepted by T-NNLS, one of the top journals in AI.
       <br><br>
       Media reports:<a href="https://mp.weixin.qq.com/s/aRTT8t35oE-UEkMAJSo9lQ">《CVPR 2020 Oral | 将SOTA行人再识别系统精度降至1.4%，中大、暗物智能等向视觉模式匹配的鲁棒性发起挑战》</a>
       <br><br>
       I have 6 patents now! [<a href="https://wanggrun.github.io/projects/pub"> patents </a>]
       <br><br>
       I have two ESI highly cited papers now!
       <br><br>
       I will serve as a reviewer of NeurIPS 2020!
       <br><br>
       Media reports:<a href="https://mp.weixin.qq.com/s/Kaj_6V5CWVV0reEMsPT6_g">《论文阅读笔记|Adaptively Connected Neural Networks》</a>    <a href="https://mp.weixin.qq.com/s/CWrpNqjAYBO9KYWl93ZQZA">《CVPR2020|如何同时保证NAS的效率和有效性?暗物智能等提出基于知识蒸馏的分块监督神经网络搜索算法》</a>
       <br><br>
       Three papers are accepted by CVPR 2020!
       <br><br>
       I have served as a reviewer of ACL 2020!
       <br><br>
       I have served as a reviewer of the journal "Information Processing and Management" (中科院分区表2区).
       <br><br>
       The pytorch implementation of ACNet will be available. <a href="https://github.com/wanggrun/Adaptively-Connected-Neural-Networks-Pytorch">code in pytorch</a>. <font color="red"><b>NEW!</b></font> 
       <br><br> 
       <font color="red"><b>Neural Architecture Search:</b></font> We are happy to announce that we have achieved a state-of-the-art 78.4% top-1 accuracy on ImageNet in a mobile setting, which is about a 2.1% gain over EfficientNet-B0.   <a href="https://arxiv.org/abs/1911.13053">paper</a>; <a href="https://github.com/jiefengpeng/DNA">code and pretrained model</a> <font color="red"><b>NEW!</b></font>
       <br><br>
       I am awarded as an  "Outstanding Student of Guangdong Province".
       <br><br>
       I have served as a reviewer of the famous journal "ISPRS Journal of Photogrammetry and Remote Sensing"(中科院分区表1区)!
       <br><br>
       I will serve as a reviewer of CVPR 2020 !
       <br><br>
       I will serve as a member of the Program Committee (PC) for AAAI 2020!
       <br><br>
       One paper is accepted by CIKM 2019! One paper entitled "Learnable Parameter Similarity" is available in Arxiv!
       <br><br>
       I have served as a reviewer for IEEE Access!
       <br><br>       
       I have served as a reviewer for T-PAMI!
       <br><br>
       The code and pretrained model of our CVPR 2019 paper "Adaptively Connected Neural Networks" have been available! <a href="https://github.com/wanggrun/Adaptively-Connected-Neural-Networks">code and pretrained model</a> <font color="red"><b>NEW!</b></font>
       <br><br>
       Our paper entitled "Weakly Supervised Person Re-identification: Cost-effective Learning with A New Benchmark" has been in Arxiv, with a large ReID benmark SYSU-30k 30 times larger  than ImageNet.  <a href="https://arxiv.org/abs/1904.03845">paper</a>; <a href="https://github.com/wanggrun/SYSU-30k">dataset</a>
       <br><br>
       I will serve as a meta reviewer for ICML 2019 workshop !
       <br><br>
       I will serve as a reviewer of PRCV 2019 !
       <br><br>
       One paper is accepted by CVPR 2019!
       <br><br>
       I will serve as a reviewer of ICCV 2019 !
       <br><br>
       I will serve as a reviewer of IJCAI 2019 !
       <br><br>
       I am serving as a reviewer of CVPR 2019 !
       <br><br>
       I have served as a reviewer of IEEE Signal Processing Letter !
       <br><br>
       One paper is accepted by NIPS2018!
       <br><br>
       Two patents have been published!
       <br><br>
       Our team won the 2nd place in Key Points Detection of Apparel Track of FashionAI Global Challenge 2018-Alibaba Cloud!
       <br><br>
       The code and pretrained model of "Training COCO 2017 Object Detection and Segmentation via Learning Feature Pyramids" have been available!<a href="https://github.com/wanggrun/Learning-Feature-Pyramids-For-COCO/blob/master/README.md">code and pretrained model</a>
       <br><br>
       Receiving the 2018 Pattern Recognition Best Paper Award!<font color="red"><b>NEW!</b></font>
       <br><br>
       The code and pretrained model of "Training ImageNet and PASCAL VOC2012 via Learning Feature Pyramids" have been available! <a href="https://github.com/wanggrun/Learning-Feature-Pyramids">code and pretrained model</a>
       <br><br>
       The code of "Batch Kalman Normalization: Towards Training Deep Neural Networks with Micro-Batches" has been available! <a href="https://github.com/wanggrun/Batch-Kalman-Normalization">code</a>
       <br><br>
       The code of "Cross-Domain Visual Matching via Generalized Similarity Measure and Feature Learning" has been release! <a href="http://www.sysu-hcp.net/cross-domain-visual-matching/">code</a>
       </p>
       <h2>Teaching</h2>
	<p>
        Pattern Recognition
        <br><br>
	SE-308: Software Design Projects
        <br><br>
        Computer Vision
  </p>
    </div>
    
</body></html>



